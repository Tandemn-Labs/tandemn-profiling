[
  {
    "tp": 8,
    "pp": 3,
    "max_input_length": 16384,
    "max_output_length": 2048,
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "status": "error",
    "error": "EngineCore encountered an issue. See stack trace (above) for the root cause.",
    "instance_type": "3x g6e.48xlarge",
    "price_per_hour": 40.05,
    "num_nodes": 3,
    "gpus_per_node": 8,
    "total_gpus": 24,
    "llm_model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "llm_tensor_parallel_size": 8,
    "llm_pipeline_parallel_size": 3,
    "llm_max_model_len": 18431,
    "llm_trust_remote_code": true,
    "llm_distributed_executor_backend": "ray",
    "llm_gpu_memory_utilization": 0.85,
    "llm_enforce_eager": true,
    "llm_enable_chunked_prefill": false,
    "llm_enable_prefix_caching": false,
    "llm_kv_transfer_config": null,
    "sampling_temperature": 0.8,
    "sampling_max_tokens": 2048,
    "sampling_min_tokens": 2048,
    "sampling_ignore_eos": true,
    "benchmark_num_samples": 30,
    "benchmark_dataset": "emozilla/pg19-test",
    "benchmark_prompt_prefix": "Please summarize the following text: ",
    "benchmark_warmup_samples": 5,
    "gpu_monitor_sample_interval": 0.5,
    "gpu_monitor_type": "distributed",
    "scheduler_monitor_sample_interval": 0.25
  }
]