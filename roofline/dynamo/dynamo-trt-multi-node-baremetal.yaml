# 2-node TensorRT-LLM (MPI) serving with NVIDIA Dynamo on AWS Spot (2x L40S total).
# Uses custom CUDA 13 AMI with TensorRT-LLM 1.1.0 pre-installed.
#
# Launch:
#   sky launch -c dyn-trtllm-qwen dynamo-trt-multi-node-baremetal.yaml
#
# Get endpoint:
#   export ENDPOINT=$(sky status --endpoint 8000 dyn-trtllm-qwen)
#   curl http://$ENDPOINT/v1/models | jq
#
# Notes:
# - Uses custom CUDA 13 AMI (ami-00e6707bcd4913b83) with TensorRT-LLM pre-installed
# - Bypasses SkyPilot's conda to use system Python (/usr/bin/python3)
# - TensorRT-LLM is in ~/.local/lib/python3.12/site-packages on the AMI
# - Runs ONE TRTLLM worker spanning BOTH GPUs (TP=2) via mpirun + trtllm-llmapi-launch
# - Node rank 0 runs etcd/nats + Dynamo OpenAI frontend
# - Node rank 1 stays alive for mpirun to SSH into 

resources:
  cloud: aws
  use_spot: true
  accelerators: L40S:1
  ports: 8000
  disk_size: 200
  region: us-east-1
  image_id: ami-07611d64052db5855  # cuda13-tensorrt-llm-ubuntu2404-20251229
  autostop:
    idle_minutes: 10
    down: true
    wait_for: jobs  # Wait for benchmark to finish, but ignore SSH

num_nodes: 2

envs:
  MODEL_PATH: Qwen/Qwen3-0.6B
  SERVED_MODEL_NAME: Qwen/Qwen3-0.6B
  HF_TOKEN: ""          # optional; pass with `--env HF_TOKEN=...` if needed
  DYN_LOG: info
  DYN_HTTP_PORT: "8000"
  DYN_STORE_KV: etcd
  DYN_REQUEST_PLANE: tcp
  FREE_GPU_MEMORY_FRACTION: "0.20"
  MAX_NUM_TOKENS: "8192"
  MAX_BATCH_SIZE: "16"

setup: |
  set -euo pipefail

  # === Deactivate conda and use system Python ===
  # SkyPilot activates conda by default; we need system Python to access
  # the TensorRT-LLM installed in user site-packages on the AMI
  unset CONDA_DEFAULT_ENV
  unset CONDA_PREFIX
  unset CONDA_PROMPT_MODIFIER
  export PATH=$(echo $PATH | tr ':' '\n' | grep -v conda | tr '\n' ':')
  
  # Force system Python (where AMI has TensorRT-LLM installed)
  export PYTHON=/usr/bin/python3
  echo "Using Python: $($PYTHON --version) at $(which $PYTHON || echo /usr/bin/python3)"
  # === END Python setup ===

  # Install Docker
  curl -fsSL https://get.docker.com -o get-docker.sh
  sudo sh get-docker.sh
  rm get-docker.sh
  sudo usermod -aG docker $USER || true
  sudo chmod 666 /var/run/docker.sock || true

  # Verify TensorRT-LLM is accessible (should be on AMI already)
  echo "=== Verifying pre-installed packages on AMI ==="
  $PYTHON -c "import tensorrt_llm; print('TensorRT-LLM:', tensorrt_llm.__version__)"
  $PYTHON -c "import sys; print('Python site-packages:', sys.path)"
  echo "=== Verification complete ==="

  # Install Dynamo (TensorRT-LLM already on AMI in user site-packages)
  $PYTHON -m pip install --break-system-packages --upgrade pip setuptools wheel
  # $PYTHON -m pip install --break-system-packages --upgrade --extra-index-url https://pypi.nvidia.com/ "tensorrt-llm>=1.2.0rc5"
  $PYTHON -m pip install --break-system-packages  "ai-dynamo" "nixl[cu12]<=0.8.0"

  # Verify Dynamo installed correctly
  $PYTHON -c "import dynamo.trtllm; print('dynamo.trtllm OK')"

  # Infra compose file (etcd + nats)
  curl -fsSL -o docker-compose.yml \
    https://raw.githubusercontent.com/ai-dynamo/dynamo/main/deploy/docker-compose.yml

run: |  
  set -euo pipefail
  
  # === Use system Python (bypass conda) ===
  unset CONDA_DEFAULT_ENV
  unset CONDA_PREFIX
  unset CONDA_PROMPT_MODIFIER
  export PATH=$(echo $PATH | tr ':' '\n' | grep -v conda | tr '\n' ':')
  export PYTHON=/usr/bin/python3
  # === END Python setup ===
  
  HEAD_IP="$(echo "$SKYPILOT_NODE_IPS" | head -n1)"
  ALL_IPS_CSV="$(echo "$SKYPILOT_NODE_IPS" | paste -sd, -)"
  TOTAL_GPUS="$((SKYPILOT_NUM_NODES * SKYPILOT_NUM_GPUS_PER_NODE))"
  
  export ETCD_ENDPOINTS="${HEAD_IP}:2379"
  export NATS_SERVER="nats://${HEAD_IP}:4222"
  export LD_LIBRARY_PATH="/usr/local/cuda-13.0/lib64:${LD_LIBRARY_PATH:-}"
  export PATH="/usr/local/cuda-13.0/bin:${PATH}"
    
  # SSH hygiene for OpenMPI rsh  
  mkdir -p ~/.ssh
  printf "Host *\nStrictHostKeyChecking no\nUserKnownHostsFile=/dev/null\n" > ~/.ssh/config
  
  if [ "${SKYPILOT_NODE_RANK}" = "0" ]; then
    echo "Head node: ${HEAD_IP}"
    echo "All node IPs: ${SKYPILOT_NODE_IPS}"
    echo "Total GPUs: ${TOTAL_GPUS} (nodes=${SKYPILOT_NUM_NODES}, gpus/node=${SKYPILOT_NUM_GPUS_PER_NODE})"
  
    # Start infra services on head (exposes 2379/4222 to the VPC)  
    docker compose -f docker-compose.yml up -d
  
    # Start OpenAI frontend on head  
    $PYTHON -m dynamo.frontend --http-port "${DYN_HTTP_PORT}" &
    sleep 10
  
    # === SSH Connectivity Check ===
    echo "Checking SSH connectivity to all nodes..."
    for ip in $(echo "$SKYPILOT_NODE_IPS"); do
      echo "Testing SSH to $ip..."
      if ! ssh -i ~/.ssh/sky-cluster-key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=10 $ip "echo 'SSH OK to $ip'"; then
        echo "ERROR: Cannot SSH to $ip"
        exit 1
      fi
    done
    echo "SSH connectivity check passed!"
    # === END SSH CHECK ===  
  
    # Launch ONE multi-node TRTLLM worker (TP = TOTAL_GPUS) across both nodes.  
    mpirun \
      -n "${TOTAL_GPUS}" \
      -H "${ALL_IPS_CSV}" \
      --mca plm_rsh_agent "ssh -i ~/.ssh/sky-cluster-key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
      -x PYTHON \
      -x PATH \
      -x LD_LIBRARY_PATH \
      -x ETCD_ENDPOINTS \
      -x NATS_SERVER \
      -x DYN_LOG \
      -x DYN_STORE_KV \
      -x DYN_REQUEST_PLANE \
      -x HF_TOKEN \
      trtllm-llmapi-launch \
        ${PYTHON} -m dynamo.trtllm \
          --model-path "${MODEL_PATH}" \
          --served-model-name "${SERVED_MODEL_NAME}" \
          --tensor-parallel-size "${TOTAL_GPUS}" \
          --gpus-per-node "${SKYPILOT_NUM_GPUS_PER_NODE}" \
          --free-gpu-memory-fraction "${FREE_GPU_MEMORY_FRACTION}" \
          --max-num-tokens "${MAX_NUM_TOKENS}" \
          --max-batch-size "${MAX_BATCH_SIZE}"
  else  
    # Keep worker node alive; mpirun will SSH in and launch the remote rank.  
    while true; do sleep 3600; done
  fi